{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4ae34006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from '/Users/amolmenon/Documents/Spring 2023/CMSC472/cmsc472_medicaldiagnosis/data.py'>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import pydicom as dicom\n",
    "\n",
    "import data\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "03f22af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = data.load_datasets()\n",
    "\n",
    "train_set = all_data['lung']['train']\n",
    "val_set = all_data['lung']['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "acedf0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.00025\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1456ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "015809b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "#         self.w1 = nn.Linear(256*256, 7)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.w2 = nn.Linear(7, 1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):     \n",
    "\n",
    "        z1 = self.w1(x)\n",
    "        a1 = self.relu(z1)\n",
    "        z2 = self.w2(a1)\n",
    "        a2 = self.sigmoid(z2)\n",
    "\n",
    "        out = a2\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1bc6cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()  \n",
    "optim = torch.optim.SGD(model.parameters(), lr = learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c3c19e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 256, 256])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_dataloader):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():   \u001b[38;5;66;03m#Does not calulate the graidents, as in val phase its not needed. Saves on memory.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;66;03m## TODO: similar to training, but no need to call backward, step, or zero_grad\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     51\u001b[0m         y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     52\u001b[0m         out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "train_loss_over_epochs = []\n",
    "val_loss_over_epochs = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #Training phase\n",
    "    model.train()  #Setting the model to train phase\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_acc = 0.\n",
    "    val_acc = 0.\n",
    "    \n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        ## TODO: fetch inputs and labels from batch\n",
    "        ## TODO: pass inputs to model\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        loss = loss_function(out, y.float().unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "\n",
    "        ## TODO: call loss function\n",
    "        ## TODO: call backward\n",
    "        ## TODO: step optimizer\n",
    "\n",
    "        ## TODO: compute accuracy and track accuracy and loss\n",
    "        y_pred = torch.round(out)\n",
    "\n",
    "        train_acc = torch.sum(torch.square(torch.sub(y, y_pred))).item() / (y.size(dim=0))\n",
    "        train_acc = (torch.squeeze(y_pred).eq(y)).sum().item() / y.size(dim=0)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        ## IMPORTANT: don't forget to call zero_grad on the optimizer between batches!!!\n",
    "\n",
    "    #Validation phase\n",
    "    model.eval()  #Setting the model to eval mode, hence making it deterministic.\n",
    "    for idx, batch in enumerate(val_dataloader):\n",
    "        with torch.no_grad():   #Does not calulate the graidents, as in val phase its not needed. Saves on memory.\n",
    "            ## TODO: similar to training, but no need to call backward, step, or zero_grad\n",
    "            x = batch['image']\n",
    "            y = batch['label']\n",
    "            out = model.forward(x)\n",
    "            loss = loss_function(out, y.float().unsqueeze(1))\n",
    "\n",
    "            y_pred = torch.round(out)\n",
    "            val_acc = (torch.squeeze(y_pred).eq(y)).sum().item() / y.size(dim=0)\n",
    "            val_loss.append(loss.item())\n",
    "    train_loss_over_epochs.append(np.mean(train_loss))\n",
    "    val_loss_over_epochs.append(np.mean(val_loss))\n",
    "    ## DO NOT change the next two lines\n",
    "    if epoch%100==0:\n",
    "        print(\"Epoch : {}, Train loss: {} , Train Acc: {}, Val loss: {}, Val acc: {}\".format(epoch, np.mean(train_loss), train_acc, np.mean(val_loss), val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35dfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
