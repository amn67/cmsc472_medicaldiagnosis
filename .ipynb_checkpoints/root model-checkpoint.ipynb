{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae34006",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from '/Users/amolmenon/Documents/Spring 2023/CMSC472/cmsc472_medicaldiagnosis/data.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import pydicom as dicom\n",
    "\n",
    "import data\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import models\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "importlib.reload(models)\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961afe8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = data.load_datasets()\n",
    "\n",
    "train_set = all_data['combined']['train']\n",
    "val_set = all_data['combined']['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f404d0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c68852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2eb1d81-3f9a-4a39-b794-e3e682b848b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiClassNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiClassNet, self).__init__()\n",
    "        self.procedure = nn.Sequential(\n",
    "            nn.Linear(256 * 256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 256 * 256)\n",
    "        return self.procedure(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d627129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = len(all_data.keys()) - 1\n",
    "model = MultiClassNet(num_classes)\n",
    "optim = torch.optim.SGD(model.parameters(), lr = learning_rate) \n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9bc4a",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train loss: 1.06393 , Train Acc: 0.7778, Val loss: 1.00604, Val acc: 1.0000\n",
      "Epoch : 1, Train loss: 1.00105 , Train Acc: 0.7778, Val loss: 0.93983, Val acc: 1.0000\n",
      "Epoch : 2, Train loss: 0.93901 , Train Acc: 1.0000, Val loss: 0.88480, Val acc: 1.0000\n",
      "Epoch : 3, Train loss: 0.90131 , Train Acc: 1.0000, Val loss: 0.84625, Val acc: 1.0000\n",
      "Epoch : 4, Train loss: 0.87734 , Train Acc: 0.7778, Val loss: 0.81782, Val acc: 1.0000\n",
      "Epoch : 5, Train loss: 0.85239 , Train Acc: 0.7778, Val loss: 0.79492, Val acc: 1.0000\n",
      "Epoch : 6, Train loss: 0.81485 , Train Acc: 1.0000, Val loss: 0.77585, Val acc: 1.0000\n",
      "Epoch : 7, Train loss: 0.80371 , Train Acc: 1.0000, Val loss: 0.76010, Val acc: 1.0000\n",
      "Epoch : 8, Train loss: 0.77860 , Train Acc: 1.0000, Val loss: 0.74710, Val acc: 1.0000\n",
      "Epoch : 9, Train loss: 0.77418 , Train Acc: 1.0000, Val loss: 0.73543, Val acc: 1.0000\n",
      "Epoch : 10, Train loss: 0.78115 , Train Acc: 0.5556, Val loss: 0.72632, Val acc: 1.0000\n",
      "Epoch : 11, Train loss: 0.75575 , Train Acc: 1.0000, Val loss: 0.71723, Val acc: 1.0000\n",
      "Epoch : 12, Train loss: 0.74293 , Train Acc: 1.0000, Val loss: 0.70947, Val acc: 1.0000\n",
      "Epoch : 13, Train loss: 0.73246 , Train Acc: 1.0000, Val loss: 0.70273, Val acc: 1.0000\n",
      "Epoch : 14, Train loss: 0.73755 , Train Acc: 0.7778, Val loss: 0.69704, Val acc: 1.0000\n",
      "Epoch : 15, Train loss: 0.71803 , Train Acc: 1.0000, Val loss: 0.69172, Val acc: 1.0000\n",
      "Epoch : 16, Train loss: 0.71556 , Train Acc: 1.0000, Val loss: 0.68680, Val acc: 1.0000\n",
      "Epoch : 17, Train loss: 0.71313 , Train Acc: 1.0000, Val loss: 0.68262, Val acc: 1.0000\n",
      "Epoch : 18, Train loss: 0.71999 , Train Acc: 0.7778, Val loss: 0.67894, Val acc: 1.0000\n",
      "Epoch : 19, Train loss: 0.69562 , Train Acc: 1.0000, Val loss: 0.67558, Val acc: 1.0000\n",
      "Epoch : 20, Train loss: 0.69307 , Train Acc: 1.0000, Val loss: 0.67244, Val acc: 1.0000\n",
      "Epoch : 21, Train loss: 0.71084 , Train Acc: 0.7778, Val loss: 0.66959, Val acc: 1.0000\n",
      "Epoch : 22, Train loss: 0.69319 , Train Acc: 1.0000, Val loss: 0.66679, Val acc: 1.0000\n",
      "Epoch : 23, Train loss: 0.68445 , Train Acc: 1.0000, Val loss: 0.66436, Val acc: 1.0000\n",
      "Epoch : 24, Train loss: 0.70359 , Train Acc: 0.7778, Val loss: 0.66212, Val acc: 1.0000\n",
      "Epoch : 25, Train loss: 0.67820 , Train Acc: 1.0000, Val loss: 0.66006, Val acc: 1.0000\n",
      "Epoch : 26, Train loss: 0.69217 , Train Acc: 0.7778, Val loss: 0.65809, Val acc: 1.0000\n",
      "Epoch : 27, Train loss: 0.69315 , Train Acc: 0.7778, Val loss: 0.65640, Val acc: 1.0000\n",
      "Epoch : 28, Train loss: 0.67150 , Train Acc: 1.0000, Val loss: 0.65468, Val acc: 1.0000\n",
      "Epoch : 29, Train loss: 0.67448 , Train Acc: 1.0000, Val loss: 0.65302, Val acc: 1.0000\n",
      "Epoch : 30, Train loss: 0.66935 , Train Acc: 1.0000, Val loss: 0.65147, Val acc: 1.0000\n",
      "Epoch : 31, Train loss: 0.67145 , Train Acc: 1.0000, Val loss: 0.65002, Val acc: 1.0000\n",
      "Epoch : 32, Train loss: 0.66580 , Train Acc: 1.0000, Val loss: 0.64865, Val acc: 1.0000\n",
      "Epoch : 33, Train loss: 0.68059 , Train Acc: 0.7778, Val loss: 0.64748, Val acc: 1.0000\n",
      "Epoch : 34, Train loss: 0.66156 , Train Acc: 1.0000, Val loss: 0.64631, Val acc: 1.0000\n",
      "Epoch : 35, Train loss: 0.66292 , Train Acc: 1.0000, Val loss: 0.64520, Val acc: 1.0000\n",
      "Epoch : 36, Train loss: 0.65976 , Train Acc: 1.0000, Val loss: 0.64412, Val acc: 1.0000\n",
      "Epoch : 37, Train loss: 0.66459 , Train Acc: 1.0000, Val loss: 0.64304, Val acc: 1.0000\n",
      "Epoch : 38, Train loss: 0.66633 , Train Acc: 1.0000, Val loss: 0.64203, Val acc: 1.0000\n",
      "Epoch : 39, Train loss: 0.67079 , Train Acc: 0.7778, Val loss: 0.64114, Val acc: 1.0000\n",
      "Epoch : 40, Train loss: 0.65633 , Train Acc: 1.0000, Val loss: 0.64028, Val acc: 1.0000\n",
      "Epoch : 41, Train loss: 0.67306 , Train Acc: 0.7778, Val loss: 0.63950, Val acc: 1.0000\n",
      "Epoch : 42, Train loss: 0.66062 , Train Acc: 1.0000, Val loss: 0.63867, Val acc: 1.0000\n",
      "Epoch : 43, Train loss: 0.65410 , Train Acc: 1.0000, Val loss: 0.63787, Val acc: 1.0000\n",
      "Epoch : 44, Train loss: 0.66837 , Train Acc: 0.7778, Val loss: 0.63717, Val acc: 1.0000\n",
      "Epoch : 45, Train loss: 0.65782 , Train Acc: 1.0000, Val loss: 0.63642, Val acc: 1.0000\n",
      "Epoch : 46, Train loss: 0.65033 , Train Acc: 1.0000, Val loss: 0.63569, Val acc: 1.0000\n",
      "Epoch : 47, Train loss: 0.64958 , Train Acc: 1.0000, Val loss: 0.63504, Val acc: 1.0000\n",
      "Epoch : 48, Train loss: 0.66240 , Train Acc: 0.7778, Val loss: 0.63442, Val acc: 1.0000\n",
      "Epoch : 49, Train loss: 0.65100 , Train Acc: 1.0000, Val loss: 0.63379, Val acc: 1.0000\n",
      "Epoch : 50, Train loss: 0.65103 , Train Acc: 1.0000, Val loss: 0.63317, Val acc: 1.0000\n",
      "Epoch : 51, Train loss: 0.64698 , Train Acc: 1.0000, Val loss: 0.63259, Val acc: 1.0000\n",
      "Epoch : 52, Train loss: 0.65387 , Train Acc: 1.0000, Val loss: 0.63200, Val acc: 1.0000\n",
      "Epoch : 53, Train loss: 0.64903 , Train Acc: 1.0000, Val loss: 0.63148, Val acc: 1.0000\n",
      "Epoch : 54, Train loss: 0.66164 , Train Acc: 0.7778, Val loss: 0.63102, Val acc: 1.0000\n",
      "Epoch : 55, Train loss: 0.64434 , Train Acc: 1.0000, Val loss: 0.63051, Val acc: 1.0000\n",
      "Epoch : 56, Train loss: 0.66272 , Train Acc: 0.7778, Val loss: 0.63006, Val acc: 1.0000\n",
      "Epoch : 57, Train loss: 0.64736 , Train Acc: 1.0000, Val loss: 0.62956, Val acc: 1.0000\n",
      "Epoch : 58, Train loss: 0.64536 , Train Acc: 1.0000, Val loss: 0.62908, Val acc: 1.0000\n",
      "Epoch : 59, Train loss: 0.64382 , Train Acc: 1.0000, Val loss: 0.62861, Val acc: 1.0000\n",
      "Epoch : 60, Train loss: 0.65564 , Train Acc: 0.7778, Val loss: 0.62821, Val acc: 1.0000\n",
      "Epoch : 61, Train loss: 0.64127 , Train Acc: 1.0000, Val loss: 0.62778, Val acc: 1.0000\n",
      "Epoch : 62, Train loss: 0.64137 , Train Acc: 1.0000, Val loss: 0.62738, Val acc: 1.0000\n",
      "Epoch : 63, Train loss: 0.64158 , Train Acc: 1.0000, Val loss: 0.62697, Val acc: 1.0000\n",
      "Epoch : 64, Train loss: 0.64244 , Train Acc: 1.0000, Val loss: 0.62658, Val acc: 1.0000\n",
      "Epoch : 65, Train loss: 0.63912 , Train Acc: 1.0000, Val loss: 0.62621, Val acc: 1.0000\n",
      "Epoch : 66, Train loss: 0.64049 , Train Acc: 1.0000, Val loss: 0.62582, Val acc: 1.0000\n",
      "Epoch : 67, Train loss: 0.63912 , Train Acc: 1.0000, Val loss: 0.62547, Val acc: 1.0000\n",
      "Epoch : 68, Train loss: 0.63830 , Train Acc: 1.0000, Val loss: 0.62513, Val acc: 1.0000\n",
      "Epoch : 69, Train loss: 0.63730 , Train Acc: 1.0000, Val loss: 0.62481, Val acc: 1.0000\n",
      "Epoch : 70, Train loss: 0.66657 , Train Acc: 0.5556, Val loss: 0.62451, Val acc: 1.0000\n",
      "Epoch : 71, Train loss: 0.63693 , Train Acc: 1.0000, Val loss: 0.62418, Val acc: 1.0000\n",
      "Epoch : 72, Train loss: 0.63818 , Train Acc: 1.0000, Val loss: 0.62384, Val acc: 1.0000\n",
      "Epoch : 73, Train loss: 0.63603 , Train Acc: 1.0000, Val loss: 0.62354, Val acc: 1.0000\n",
      "Epoch : 74, Train loss: 0.63666 , Train Acc: 1.0000, Val loss: 0.62321, Val acc: 1.0000\n",
      "Epoch : 75, Train loss: 0.63982 , Train Acc: 1.0000, Val loss: 0.62289, Val acc: 1.0000\n",
      "Epoch : 76, Train loss: 0.65072 , Train Acc: 0.7778, Val loss: 0.62262, Val acc: 1.0000\n",
      "Epoch : 77, Train loss: 0.63525 , Train Acc: 1.0000, Val loss: 0.62234, Val acc: 1.0000\n",
      "Epoch : 78, Train loss: 0.64963 , Train Acc: 0.7778, Val loss: 0.62208, Val acc: 1.0000\n",
      "Epoch : 79, Train loss: 0.63641 , Train Acc: 1.0000, Val loss: 0.62179, Val acc: 1.0000\n",
      "Epoch : 80, Train loss: 0.63654 , Train Acc: 1.0000, Val loss: 0.62152, Val acc: 1.0000\n",
      "Epoch : 81, Train loss: 0.65070 , Train Acc: 0.7778, Val loss: 0.62127, Val acc: 1.0000\n",
      "Epoch : 82, Train loss: 0.63413 , Train Acc: 1.0000, Val loss: 0.62098, Val acc: 1.0000\n",
      "Epoch : 83, Train loss: 0.64765 , Train Acc: 0.7778, Val loss: 0.62072, Val acc: 1.0000\n",
      "Epoch : 84, Train loss: 0.66232 , Train Acc: 0.5556, Val loss: 0.62048, Val acc: 1.0000\n",
      "Epoch : 85, Train loss: 0.64873 , Train Acc: 0.7778, Val loss: 0.62025, Val acc: 1.0000\n",
      "Epoch : 86, Train loss: 0.63250 , Train Acc: 1.0000, Val loss: 0.61999, Val acc: 1.0000\n",
      "Epoch : 87, Train loss: 0.63257 , Train Acc: 1.0000, Val loss: 0.61974, Val acc: 1.0000\n",
      "Epoch : 88, Train loss: 0.63820 , Train Acc: 1.0000, Val loss: 0.61946, Val acc: 1.0000\n",
      "Epoch : 89, Train loss: 0.63162 , Train Acc: 1.0000, Val loss: 0.61921, Val acc: 1.0000\n",
      "Epoch : 90, Train loss: 0.63396 , Train Acc: 1.0000, Val loss: 0.61898, Val acc: 1.0000\n",
      "Epoch : 91, Train loss: 0.63148 , Train Acc: 1.0000, Val loss: 0.61875, Val acc: 1.0000\n",
      "Epoch : 92, Train loss: 0.63280 , Train Acc: 1.0000, Val loss: 0.61851, Val acc: 1.0000\n",
      "Epoch : 93, Train loss: 0.64368 , Train Acc: 0.7778, Val loss: 0.61826, Val acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 94, Train loss: 0.63540 , Train Acc: 1.0000, Val loss: 0.61803, Val acc: 1.0000\n",
      "Epoch : 95, Train loss: 0.63001 , Train Acc: 1.0000, Val loss: 0.61782, Val acc: 1.0000\n",
      "Epoch : 96, Train loss: 0.62989 , Train Acc: 1.0000, Val loss: 0.61761, Val acc: 1.0000\n",
      "Epoch : 97, Train loss: 0.64552 , Train Acc: 0.7778, Val loss: 0.61745, Val acc: 1.0000\n",
      "Epoch : 98, Train loss: 0.66345 , Train Acc: 0.5556, Val loss: 0.61731, Val acc: 1.0000\n",
      "Epoch : 99, Train loss: 0.66205 , Train Acc: 0.5556, Val loss: 0.61719, Val acc: 1.0000\n",
      "Epoch : 100, Train loss: 0.63048 , Train Acc: 1.0000, Val loss: 0.61695, Val acc: 1.0000\n",
      "Epoch : 101, Train loss: 0.62919 , Train Acc: 1.0000, Val loss: 0.61674, Val acc: 1.0000\n",
      "Epoch : 102, Train loss: 0.64535 , Train Acc: 0.7778, Val loss: 0.61657, Val acc: 1.0000\n",
      "Epoch : 103, Train loss: 0.62878 , Train Acc: 1.0000, Val loss: 0.61638, Val acc: 1.0000\n",
      "Epoch : 104, Train loss: 0.62755 , Train Acc: 1.0000, Val loss: 0.61619, Val acc: 1.0000\n",
      "Epoch : 105, Train loss: 0.62757 , Train Acc: 1.0000, Val loss: 0.61600, Val acc: 1.0000\n",
      "Epoch : 106, Train loss: 0.62964 , Train Acc: 1.0000, Val loss: 0.61578, Val acc: 1.0000\n",
      "Epoch : 107, Train loss: 0.62725 , Train Acc: 1.0000, Val loss: 0.61560, Val acc: 1.0000\n",
      "Epoch : 108, Train loss: 0.63285 , Train Acc: 1.0000, Val loss: 0.61539, Val acc: 1.0000\n",
      "Epoch : 109, Train loss: 0.62767 , Train Acc: 1.0000, Val loss: 0.61521, Val acc: 1.0000\n",
      "Epoch : 110, Train loss: 0.62666 , Train Acc: 1.0000, Val loss: 0.61502, Val acc: 1.0000\n",
      "Epoch : 111, Train loss: 0.62665 , Train Acc: 1.0000, Val loss: 0.61483, Val acc: 1.0000\n",
      "Epoch : 112, Train loss: 0.64303 , Train Acc: 0.7778, Val loss: 0.61468, Val acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "train_loss_epochs = []\n",
    "val_loss_epochs = []\n",
    "train_accs_epochs = []\n",
    "val_accs_epochs = []\n",
    "\n",
    "pixel_means = train_set.images.mean(dim=0, keepdim=True)\n",
    "pixel_stds = train_set.images.std(dim=0, keepdim=True, unbiased=False)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #Training phase\n",
    "    model.train()  #Setting the model to train phase\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "\n",
    "        x = batch[0]\n",
    "        x = (x-pixel_means)/pixel_stds\n",
    "        x = x.unsqueeze(1)\n",
    "        y = batch[1].to(torch.float32)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = loss_function(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        \n",
    "        y_pred = F.one_hot(torch.argmax(out, dim=1), num_classes=num_classes)\n",
    "\n",
    "        correct = (y_pred == y).sum().item() / num_classes\n",
    "        train_acc = correct / y.size(0)\n",
    "\n",
    "\n",
    "\n",
    "        #train_acc = torch.sum(torch.square(torch.sub(y, y_pred))).item() / (y.size(dim=0))\n",
    "        #train_acc = (torch.squeeze(y_pred).eq(y)).sum().item() / y.size(dim=0)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    #Validation phase\n",
    "    model.eval()  #Setting the model to eval mode, hence making it deterministic.\n",
    "    for idx, batch in enumerate(val_dataloader):\n",
    "        with torch.no_grad():   #Does not calulate the graidents, as in val phase its not needed. Saves on memory.\n",
    "            x = batch[0]\n",
    "            x = (x-pixel_means)/pixel_stds\n",
    "            x = x.unsqueeze(1)\n",
    "            y = batch[1].to(torch.float32)\n",
    "            out = model.forward(x)\n",
    "            loss = loss_function(out, y)\n",
    "            \n",
    "            y_pred = F.one_hot(torch.argmax(out, dim=1), num_classes=num_classes)\n",
    "            \n",
    "            correct = (y_pred == y).sum().item() / num_classes\n",
    "            val_acc = correct / y.size(0)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            val_accs.append(val_acc)\n",
    "    train_loss_epochs.append(np.mean(train_loss))\n",
    "    val_loss_epochs.append(np.mean(val_loss))\n",
    "    train_accs_epochs.append(np.mean(train_accs))\n",
    "    val_accs_epochs.append(np.mean(val_accs))\n",
    "    if epoch%1==0:\n",
    "        print(\"Epoch : {}, Train loss: {:.5f} , Train Acc: {:.4f}, Val loss: {:.5f}, Val acc: {:.4f}\".format(epoch, np.mean(train_loss), np.mean(train_acc), np.mean(val_loss), np.mean(val_acc)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4fb6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(range(1, epochs+1), train_loss_epochs, label='train loss')\n",
    "plt.plot(range(1, epochs+1), val_loss_epochs, label='val loss')\n",
    "plt.xlabel(\"Epoch\", size=14)\n",
    "plt.ylabel(\"Loss\", size=14)\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecda4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = all_data['combined']['test']\n",
    "parts = test_set.parts\n",
    "parts_idx_map = test_set.parts_idx\n",
    "loaded_part_models = []\n",
    "for part in parts:\n",
    "    m = models.get_model_class(part)\n",
    "    m.load_state_dict(torch.load('./trained_models/{}_meta_weights.pth'.format(part)))\n",
    "    loaded_part_models.append(m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_set, batch_size=len(test_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_part_preds = []\n",
    "test_benign_preds = []\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "for i in range(len(test_set)):\n",
    "    image, part, binary_label = test_set.images[i], test_set.labels[i], test_set.binary_labels[i]\n",
    "    with torch.no_grad():\n",
    "        # Predict which body part\n",
    "        x = image.unsqueeze(0)\n",
    "        x_scaled = (x-pixel_means)/pixel_stds\n",
    "        x_scaled = x_scaled.unsqueeze(1)\n",
    "        x = x.unsqueeze(1)\n",
    "        out = model.forward(x_scaled)\n",
    "        y_pred = F.one_hot(torch.argmax(out, dim=1), num_classes=num_classes)\n",
    "\n",
    "        idx = torch.argmax(y_pred).item()\n",
    "        \n",
    "        # Choose next model and predict if cancer or no cancer\n",
    "        leaf_model = loaded_part_models[idx]\n",
    "        leaf_model.eval()\n",
    "        out_2 = leaf_model.forward(x)\n",
    "        y2_pred = int(out_2.round().item())\n",
    "        \n",
    "        test_part_preds.append(y_pred)\n",
    "        test_benign_preds.append(y2_pred)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4353e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_part_preds = torch.stack(test_part_preds).squeeze(1)\n",
    "test_benign_preds = torch.tensor(test_benign_preds).unsqueeze(1)\n",
    "\n",
    "correct = (test_part_preds == test_set.labels).sum().item() / num_classes\n",
    "test_acc = correct / test_set.labels.size(0)\n",
    "print(test_acc)\n",
    "\n",
    "test_acc_2 = (torch.squeeze(test_benign_preds).eq(test_set.binary_labels)).sum().item() / test_set.binary_labels.size(dim=0)\n",
    "print(test_acc_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "true_body_part_labels = torch.argmax(test_set.labels, dim=1).numpy()\n",
    "pred_body_part_labels = torch.argmax(test_part_preds, dim=1).numpy()\n",
    "\n",
    "body_part_cm = confusion_matrix(true_body_part_labels, pred_body_part_labels)\n",
    "\n",
    "binary_preds = (test_benign_preds > 0.5).int().squeeze().numpy()\n",
    "binary_labels = test_set.binary_labels.numpy()\n",
    "\n",
    "cancer_cm_list = []\n",
    "for part in range(3):\n",
    "    indices = np.where(true_body_part_labels == part)\n",
    "    cancer_cm = confusion_matrix(binary_labels[indices], binary_preds[indices])\n",
    "    cancer_cm_list.append(cancer_cm)\n",
    "\n",
    "cancer_cm_combined = np.sum(cancer_cm_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Plot confusion matrix for body part classification\n",
    "plt.figure()\n",
    "plot_confusion_matrix(body_part_cm, classes=parts,\n",
    "                      title='Confusion matrix for body part classification')\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix for cancer classification\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cancer_cm_combined, classes=['No cancer', 'Cancer'],\n",
    "                      title='Confusion matrix for cancer classification')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723527b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as nd\n",
    "\n",
    "def surfd(input1, input2, sampling=1, connectivity=1):\n",
    "    \n",
    "    input_1 = np.atleast_1d(input1.astype(bool))\n",
    "    input_2 = np.atleast_1d(input2.astype(bool))\n",
    "\t\n",
    "    conn = nd.generate_binary_structure(input_1.ndim, connectivity)\n",
    "\n",
    "    S = input_1 ^ nd.binary_erosion(input_1, conn)\n",
    "    Sprime = input_2 ^ nd.binary_erosion(input_2, conn)\n",
    "\t\n",
    "    dta = nd.distance_transform_edt(~S,sampling)\n",
    "    dtb = nd.distance_transform_edt(~Sprime,sampling)\n",
    "    \n",
    "    sds = np.concatenate([np.ravel(dta[Sprime!=0]), np.ravel(dtb[S!=0])])\n",
    "        \n",
    "    return sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23384da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision for Body Part Classification: %.3f' % precision_score(true_body_part_labels, pred_body_part_labels, average='weighted'))\n",
    "print('Recall for Body Part Classification : %.3f' % recall_score(true_body_part_labels, pred_body_part_labels, average='weighted'))\n",
    "print('F1 Score (DICE Coefficient) for Body Part Classification: %.3f' % f1_score(true_body_part_labels, pred_body_part_labels, average='weighted'))\n",
    "print('Mean Surface Distance for Body Part Classification %.3f'% surfd(true_body_part_labels, pred_body_part_labels).mean())\n",
    "print('Cohen Kappa Score for Body Part Classification: %.3f' % cohen_kappa_score(true_body_part_labels, pred_body_part_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Precision for Cancer Classification: %.3f' % precision_score(binary_labels, binary_preds, average='weighted'))\n",
    "print('Recall for Cancer Classification : %.3f' % recall_score(binary_labels, binary_preds, average='weighted'))\n",
    "print('F1 Score (DICE Coefficient) for Cancer Classification: %.3f' % f1_score(binary_labels, binary_preds, average='weighted'))\n",
    "print('Mean Surface Distance for Cancer Classification %.3f'% surfd(binary_labels, binary_preds).mean())\n",
    "print('Cohen Kappa Score for Cancer Classification: %.3f' % cohen_kappa_score(binary_labels, binary_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a2860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cancer_type = ['Lung', 'Breast', 'Brain']\n",
    "for p in range(3):\n",
    "    indices = np.where(true_body_part_labels == p)\n",
    "    cancer_labels = []\n",
    "    cancer_preds=[]\n",
    "    print('Precision for ' + cancer_type[p]+ ' Cancer Classification: %.3f' % precision_score(binary_labels[indices], binary_preds[indices], average='weighted', zero_division= False))\n",
    "    print('Recall for  ' +cancer_type[p]+ '  Cancer Classification : %.3f' % recall_score(binary_labels[indices], binary_preds[indices], average='weighted', zero_division= False))\n",
    "    print('F1 Score (DICE Coefficient) for ' + cancer_type[p]+ ' Cancer Classification: %.3f' % f1_score(binary_labels[indices], binary_preds[indices], average='weighted'))\n",
    "    print('Mean Surface Distance for ' + cancer_type[p] + ' Cancer Classification %.3f'% surfd(binary_labels[indices], binary_preds[indices]).mean())\n",
    "    print('Cohen Kappa Score for ' + cancer_type[p] + ' Cancer Classification: %.3f\\n' % cohen_kappa_score(binary_labels[indices], binary_preds[indices]))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9f97c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
