{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae34006",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pydicom as dicom\n",
    "\n",
    "import pickle\n",
    "import data\n",
    "import models\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "importlib.reload(data)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961afe8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = data.load_datasets()\n",
    "\n",
    "train_set = all_data['lung']['train']\n",
    "val_set = all_data['lung']['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f404d0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 0.00025\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c68852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d627129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.get_model_class('lung')\n",
    "optim = torch.optim.SGD(model.parameters(), lr = learning_rate) \n",
    "loss_function = nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9bc4a",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "train_loss_epochs = []\n",
    "val_loss_epochs = []\n",
    "train_accs_epochs = []\n",
    "val_accs_epochs = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #Training phase\n",
    "    model.train()  #Setting the model to train phase\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "\n",
    "        x = batch[0].unsqueeze(1)\n",
    "        x = x\n",
    "        y = batch[1]\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        loss = loss_function(out, y.float().unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "\n",
    "        y_pred = torch.round(out)\n",
    "\n",
    "        train_acc = torch.sum(torch.square(torch.sub(y, y_pred))).item() / (y.size(dim=0))\n",
    "        train_acc = (torch.squeeze(y_pred).eq(y)).sum().item() / y.size(dim=0)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    #Validation phase\n",
    "    model.eval()  #Setting the model to eval mode, hence making it deterministic.\n",
    "    for idx, batch in enumerate(val_dataloader):\n",
    "        with torch.no_grad():   #Does not calulate the graidents, as in val phase its not needed. Saves on memory.\n",
    "            x = batch[0].unsqueeze(1)\n",
    "            y = batch[1]\n",
    "            out = model.forward(x)\n",
    "            loss = loss_function(out, y.float().unsqueeze(1))\n",
    "            y_pred = torch.round(out)\n",
    "            val_acc = (torch.squeeze(y_pred).eq(y)).sum().item() / y.size(dim=0)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            val_accs.append(val_acc)\n",
    "    train_loss_epochs.append(np.mean(train_loss))\n",
    "    val_loss_epochs.append(np.mean(val_loss))\n",
    "    train_accs_epochs.append(np.mean(train_accs))\n",
    "    val_accs_epochs.append(np.mean(val_accs))\n",
    "    if epoch%1==0:\n",
    "        print(\"Epoch : {}, Train loss: {:.5f} , Train Acc: {:.4f}, Val loss: {:.5f}, Val acc: {:.4f}\".format(epoch, np.mean(train_loss), np.mean(train_acc), np.mean(val_loss), np.mean(val_acc)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4533a0e-0463-4fb4-8959-d728888fa7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f'./trained_models/meta_lung.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4fb6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(range(1, epochs+1), train_loss_epochs, label='train loss')\n",
    "plt.plot(range(1, epochs+1), val_loss_epochs, label='val loss')\n",
    "plt.xlabel(\"Epoch\", size=14)\n",
    "plt.ylabel(\"Loss\", size=14)\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7beea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(range(1, epochs+1), train_accs_epochs, label='train acc')\n",
    "plt.plot(range(1,epochs+1), val_accs_epochs, label='val acc')\n",
    "plt.xlabel(\"Epoch\", size=14)\n",
    "plt.ylabel(\"Accuracy\", size=14)\n",
    "plt.title(\"Accuracy over epochs\", size=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0895a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './trained_models/lung_meta_weights.pth')\n",
    "with open('./trained_models/lung_model_class.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525565ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 25\n",
    "plt.imshow(train_set[i][0], cmap='Greys')\n",
    "print(train_set[i][1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7c7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
