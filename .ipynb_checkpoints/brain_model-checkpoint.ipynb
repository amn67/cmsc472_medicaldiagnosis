{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae34006",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from '/Users/amolmenon/Documents/Spring 2023/CMSC472/cmsc472_medicaldiagnosis/data.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import pydicom as dicom\n",
    "\n",
    "import pickle\n",
    "import data\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961afe8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = data.load_datasets()\n",
    "\n",
    "train_set = all_data['brain']['train']\n",
    "val_set = all_data['brain']['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f404d0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c68852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6814353b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BinaryClassifierCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifierCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(-1, 64 * 32 * 32)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d627129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BinaryClassifierCNN()  \n",
    "optim = torch.optim.SGD(model.parameters(), lr = learning_rate) \n",
    "loss_function = nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9bc4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Train loss: 0.92563 , Train Acc: 0.5714, Val loss: 0.57738, Val acc: 0.8462\n",
      "Epoch : 1, Train loss: 0.53722 , Train Acc: 0.8571, Val loss: 0.51529, Val acc: 0.7692\n",
      "Epoch : 2, Train loss: 0.47233 , Train Acc: 0.9286, Val loss: 0.42094, Val acc: 0.8462\n",
      "Epoch : 3, Train loss: 0.38068 , Train Acc: 0.7857, Val loss: 0.44270, Val acc: 0.8462\n",
      "Epoch : 4, Train loss: 0.34468 , Train Acc: 1.0000, Val loss: 0.35333, Val acc: 0.8462\n",
      "Epoch : 5, Train loss: 0.28956 , Train Acc: 0.8571, Val loss: 0.30033, Val acc: 0.9615\n",
      "Epoch : 6, Train loss: 0.21965 , Train Acc: 0.9286, Val loss: 0.37512, Val acc: 0.8462\n",
      "Epoch : 7, Train loss: 0.19545 , Train Acc: 1.0000, Val loss: 0.28326, Val acc: 0.8462\n",
      "Epoch : 8, Train loss: 0.18735 , Train Acc: 1.0000, Val loss: 0.24295, Val acc: 0.8846\n",
      "Epoch : 9, Train loss: 0.18371 , Train Acc: 0.9286, Val loss: 0.22819, Val acc: 0.9231\n",
      "Epoch : 10, Train loss: 0.14857 , Train Acc: 0.9286, Val loss: 0.48157, Val acc: 0.8077\n",
      "Epoch : 11, Train loss: 0.15230 , Train Acc: 0.8571, Val loss: 0.26374, Val acc: 0.9231\n",
      "Epoch : 12, Train loss: 0.17186 , Train Acc: 1.0000, Val loss: 0.19249, Val acc: 0.9615\n",
      "Epoch : 13, Train loss: 0.10886 , Train Acc: 1.0000, Val loss: 0.21067, Val acc: 0.9615\n",
      "Epoch : 14, Train loss: 0.11318 , Train Acc: 1.0000, Val loss: 0.26543, Val acc: 0.8846\n",
      "Epoch : 15, Train loss: 0.09977 , Train Acc: 0.9286, Val loss: 0.19149, Val acc: 0.9615\n",
      "Epoch : 16, Train loss: 0.08468 , Train Acc: 1.0000, Val loss: 0.21418, Val acc: 0.9231\n"
     ]
    }
   ],
   "source": [
    "train_loss_epochs = []\n",
    "val_loss_epochs = []\n",
    "train_accs_epochs = []\n",
    "val_accs_epochs = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    #Training phase\n",
    "    model.train()  #Setting the model to train phase\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "\n",
    "        x = batch[0].unsqueeze(1)\n",
    "        y = batch[1]\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        loss = loss_function(out, y.float().unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "\n",
    "        y_pred = torch.round(torch.flatten(out))\n",
    "\n",
    "        train_acc = torch.sum(torch.square(torch.sub(y, y_pred))).item() / (y.size(dim=0))\n",
    "        train_acc = (torch.squeeze(y_pred).eq(y)).sum().item() / y.size(dim=0)\n",
    "        train_accs.append(train_acc)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "    #Validation phase\n",
    "    model.eval()  #Setting the model to eval mode, hence making it deterministic.\n",
    "    for idx, batch in enumerate(val_dataloader):\n",
    "        with torch.no_grad():   #Does not calulate the graidents, as in val phase its not needed. Saves on memory.\n",
    "            x = batch[0].unsqueeze(1)\n",
    "            y = batch[1]\n",
    "            out = model.forward(x)\n",
    "            loss = loss_function(out, y.float().unsqueeze(1))\n",
    "            y_pred = torch.round(out)\n",
    "            val_acc = (torch.squeeze(y_pred).eq(y)).sum().item() / y.size(dim=0)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            val_accs.append(val_acc)\n",
    "    train_loss_epochs.append(np.mean(train_loss))\n",
    "    val_loss_epochs.append(np.mean(val_loss))\n",
    "    train_accs_epochs.append(np.mean(train_accs))\n",
    "    val_accs_epochs.append(np.mean(val_accs))\n",
    "    if epoch%1==0:\n",
    "        print(\"Epoch : {}, Train loss: {:.5f} , Train Acc: {:.4f}, Val loss: {:.5f}, Val acc: {:.4f}\".format(epoch, np.mean(train_loss), np.mean(train_acc), np.mean(val_loss), np.mean(val_acc)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4fb6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(range(1, epochs+1), train_loss_epochs, label='train loss')\n",
    "plt.plot(range(1, epochs+1), val_loss_epochs, label='val loss')\n",
    "plt.xlabel(\"Epoch\", size=14)\n",
    "plt.ylabel(\"Loss\", size=14)\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7beea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(range(1, epochs+1), train_accs_epochs, label='train acc')\n",
    "plt.plot(range(1,epochs+1), val_accs_epochs, label='val acc')\n",
    "plt.xlabel(\"Epoch\", size=14)\n",
    "plt.ylabel(\"Accuracy\", size=14)\n",
    "plt.title(\"Accuracy over epochs\", size=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './trained_models/brain_meta_weights.pth')\n",
    "with open('./trained_models/brain_model_class.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424c59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
